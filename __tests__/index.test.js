import { remark } from 'remark'
import { visit } from 'unist-util-visit'

import plugin from '../'

const processor = remark().data(`settings`, {
  commonmark: true,
  footnotes: true,
  pedantic: true,
})

describe('nothing should be changed', () => {
  it('no line break exists', () => {
    const markdownAST = processor.parse('ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚')
    const transformed = plugin({ markdownAST }, {})

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚')

      expect(node).toMatchSnapshot()
    })
  })

  it('Latin characters are separated with a line break', () => {
    const markdownAST = processor.parse(`Good morning.\nHave a nice day.`)
    const transformed = plugin({ markdownAST }, {})

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe(`Good morning.\nHave a nice day.`)
      expect(node).toMatchSnapshot()
    })
  })

  it('CJK characters are separated with a space', () => {
    const markdownAST = processor.parse('ãŠã¯ã‚ˆã† ã”ã–ã„ã¾ã™ã€‚')
    const transformed = plugin({ markdownAST }, {})

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ãŠã¯ã‚ˆã† ã”ã–ã„ã¾ã™ã€‚')
      expect(node).toMatchSnapshot()
    })
  })

  it('CJK characters are separated with a line break, but an extra space exists', () => {
    const markdownAST = processor.parse(`
    ãŠã¯ã‚ˆã†
     ã”ã–ã„ã¾ã™ã€‚`)
    const transformed = plugin({ markdownAST }, {})

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe(`
    ãŠã¯ã‚ˆã†
     ã”ã–ã„ã¾ã™ã€‚`)
      expect(node).toMatchSnapshot()
    })
  })
})

describe('a line break should be removed', () => {
  it('Chinese characters are separeted with a line feed', () => {
    const markdownAST = processor.parse('ä¸Šåˆå¥½ã€‚\nè¿™æ˜¯ä¸ªç¾ä¸½çš„æ—¥å­ã€‚')
    const transformed = plugin({ markdownAST }, {})

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ä¸Šåˆå¥½ã€‚è¿™æ˜¯ä¸ªç¾ä¸½çš„æ—¥å­ã€‚')
      expect(node).toMatchSnapshot()
    })
  })

  it('Chinese characters are separeted with a carriage return', () => {
    const markdownAST = processor.parse('ä¸Šåˆå¥½ã€‚\rè¿™æ˜¯ä¸ªç¾ä¸½çš„æ—¥å­ã€‚')
    const transformed = plugin({ markdownAST }, {})

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ä¸Šåˆå¥½ã€‚è¿™æ˜¯ä¸ªç¾ä¸½çš„æ—¥å­ã€‚')
      expect(node).toMatchSnapshot()
    })
  })

  it('Chinese characters are separeted with a carriage return and a line feed', () => {
    const markdownAST = processor.parse('ä¸Šåˆå¥½ã€‚\r\nè¿™æ˜¯ä¸ªç¾ä¸½çš„æ—¥å­ã€‚')
    const transformed = plugin({ markdownAST }, {})

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ä¸Šåˆå¥½ã€‚è¿™æ˜¯ä¸ªç¾ä¸½çš„æ—¥å­ã€‚')
      expect(node).toMatchSnapshot()
    })
  })

  it('Japanese characters are separeted with a line feed', () => {
    const markdownAST = processor.parse(
      'ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚\nä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚'
    )
    const transformed = plugin({ markdownAST }, {})

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚')
      expect(node).toMatchSnapshot()
    })
  })
})

describe('Hangul support', () => {
  it('Hangul characters between a line feed without the option', () => {
    const markdownAST = processor.parse('ì•ˆë…•\ní•˜ì„¸ìš”')
    const transformed = plugin({ markdownAST }, { includeHangul: false })

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ì•ˆë…•\ní•˜ì„¸ìš”')
      expect(node).toMatchSnapshot()
    })
  })
  it('Hangul characters between a line feed with the option', () => {
    const markdownAST = processor.parse('ì•ˆë…•\ní•˜ì„¸ìš”')
    const transformed = plugin({ markdownAST }, { includeHangul: true })

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ì•ˆë…•í•˜ì„¸ìš”')
      expect(node).toMatchSnapshot()
    })
  })

  it('Latin characters between a line feed with the option', () => {
    const markdownAST = processor.parse(`Good morning.\nHave a nice day.`)
    const transformed = plugin({ markdownAST }, { includeHangul: true })

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe(`Good morning.\nHave a nice day.`)
      expect(node).toMatchSnapshot()
    })
  })
})

describe('squared Latin abbreviation support', () => {
  it('squared Latin abbreviation characters between a line feed without option', () => {
    const markdownAST = processor.parse('ã…\nã†')
    const transformed = plugin(
      { markdownAST },
      { includeSquaredLatinAbbrs: false }
    )

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ã…\nã†')
      expect(node).toMatchSnapshot()
    })
  })

  it('squared Latin abbreviation characters between a line feed with option', () => {
    const markdownAST = processor.parse('ã…\nã†')
    const transformed = plugin(
      { markdownAST },
      { includeSquaredLatinAbbrs: true }
    )

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ã…ã†')
      expect(node).toMatchSnapshot()
    })
  })

  it('Latin characters between a line feed with the option', () => {
    const markdownAST = processor.parse(`Good morning.\nHave a nice day.`)
    const transformed = plugin(
      { markdownAST },
      { includeSquaredLatinAbbrs: true }
    )

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe(`Good morning.\nHave a nice day.`)
      expect(node).toMatchSnapshot()
    })
  })
})

describe('Emoji support', () => {
  it('Emoji characters are separeted with a line feed without the option', () => {
    const markdownAST = processor.parse('ğŸ˜Š\nğŸ˜Š')
    const transformed = plugin({ markdownAST }, { includeEmoji: false })

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ğŸ˜Š\nğŸ˜Š')
      expect(node).toMatchSnapshot()
    })
  })
  it('Emoji characters are separeted with a line feed with the option', () => {
    const markdownAST = processor.parse('ğŸ˜Š\nğŸ˜Š')
    const transformed = plugin({ markdownAST }, { includeEmoji: true })

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ğŸ˜ŠğŸ˜Š')
      expect(node).toMatchSnapshot()
    })
  })

  it('Latin characters between a line feed with the option', () => {
    const markdownAST = processor.parse(`Good morning.\nHave a nice day.`)
    const transformed = plugin({ markdownAST }, { includeEmoji: true })

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe(`Good morning.\nHave a nice day.`)
      expect(node).toMatchSnapshot()
    })
  })
})

describe('additional regexp support', () => {
  it('add right parenthesis', () => {
    const markdownAST = processor.parse(
      '(å…¨è§’ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã®ã§)\nåŠè§’ã®ä¸¸æ‹¬å¼§ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚'
    )
    const transformed = plugin(
      { markdownAST },
      { additionalRegexpPairs: [{ beforeBreak: '[)]' }] }
    )

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe(
        '(å…¨è§’ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã®ã§)åŠè§’ã®ä¸¸æ‹¬å¼§ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚'
      )
      expect(node).toMatchSnapshot()
    })
  })

  it('add left parenthesis', () => {
    const markdownAST = processor.parse(
      'åŠè§’ã®ä¸¸æ‹¬å¼§\n(å…¨è§’ã®ä¸¸æ‹¬å¼§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«å«ã¾ã‚Œã‚‹)ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚'
    )
    const transformed = plugin(
      { markdownAST },
      { additionalRegexpPairs: [{ afterBreak: '[(]' }] }
    )

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe(
        'åŠè§’ã®ä¸¸æ‹¬å¼§(å…¨è§’ã®ä¸¸æ‹¬å¼§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«å«ã¾ã‚Œã‚‹)ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚'
      )
      expect(node).toMatchSnapshot()
    })
  })

  it('remove a space between a CJK character and an ASCII character', () => {
    const markdownAST = processor.parse('ä¸­æ–‡å¥å­\nan english word\næ—¥æœ¬èªã®æ–‡')
    const transformed = plugin(
      { markdownAST },
      {
        additionalRegexpPairs: [
          { beforeBreak: '\\p{ASCII}', afterBreak: undefined },
          { beforeBreak: undefined, afterBreak: '\\p{ASCII}' },
        ],
      }
    )

    visit(transformed, 'text', (node) => {
      expect(node.value).toBe('ä¸­æ–‡å¥å­an english wordæ—¥æœ¬èªã®æ–‡')
      expect(node).toMatchSnapshot()
    })
  })
})
